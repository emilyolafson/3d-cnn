{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_Regression - FS86 atlas - final.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilyolafson/3d-cnn/blob/main/SVM_Regression_FS86_atlas_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqxmqhh5gZIb"
      },
      "source": [
        "### Support Vector Regression\n",
        "\n",
        "Emily Olafson\n",
        "\n",
        "SVM regression attempts to solve the regression $f(x) = w^Tx+ b$\n",
        "\\begin{equation}\n",
        "   \\frac{1}{2}||w||^2 + \\frac{C}{m}\\sum_{i=1}^m|y_i-f(x_i)| \\\\\n",
        "\\end{equation}\n",
        "Subject to\n",
        "\\begin{equation}\n",
        "    y_iw^Tx_i -b \\leq \\epsilon, \\textbf{and } \\\\\n",
        "    y_iw^Tx_i +b \\geq \\epsilon\n",
        "\\end{equation}\n",
        "Where $x_i \\in R$ are the input variables, $y_i$ are the outputs, $C$ is the trade-off between flatness of $f(x)$ and the amount up to which deviations larger than $\\epsilon$ are tolerated.\n",
        "A Gaussian radial basis fn was used.\n",
        "\n",
        "\\begin{align}\n",
        "    k(x_i,x_j)=exp(-\\gamma^{-1}||x_i-x_j||^2)\\\\\n",
        "\\end{align}\n",
        "\n",
        "Where $\\gamma$ is a kernel parameter and $x_i$ and $x_j$ are observations. A grid search was used to optimize $\\gamma$ and $C$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2JcDXwuA-Qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dead7a7e-f833-4ef4-c78e-2104b5d6e9f1"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVR\n",
        "from sklearn import preprocessing\n",
        "import sklearn\n",
        "import scipy.io as sio\n",
        "import csv\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import GridSearchCV,cross_validate,train_test_split\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFwWhHUgO0BF"
      },
      "source": [
        "### **Processing**:\n",
        "- Deal with any missing data\n",
        "- One-hot encoding of categorical variables (ethnicity and sex)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjHRbd6T_e-X"
      },
      "source": [
        "dataset=pd.read_csv('/content/drive/My Drive/ML project/Data/compiledData_2datasets_QSM_MSConnect.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RILz0JcJLMTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f837f34-b1b4-4d73-a9f9-ee1a372c8992"
      },
      "source": [
        "dataset.isna().sum()\n",
        "dataset.isna().sum().sum()\n",
        "\n",
        "#no missing data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbLJkA-zu0Uw"
      },
      "source": [
        "#one hot encoding\n",
        "dataset=dataset.copy()\n",
        "ethnicity=dataset.pop('Ethnicity')\n",
        "dataset['white']=(ethnicity=='white')*1.0\n",
        "dataset['black']=(ethnicity=='black or african american')*1.0\n",
        "dataset['declined']=(ethnicity=='declined')*1.0\n",
        "dataset['other']=(ethnicity=='other combinations not described')*1.0\n",
        "dataset['asian']=(ethnicity=='asian')*1.0\n",
        "dataset['hispanic']=(ethnicity=='hispanic')*1.0\n",
        "\n",
        "\n",
        "sex=dataset.pop('Sex')\n",
        "dataset['Female']=(sex=='F')*1.0\n",
        "dataset['Male']=(sex=='M')*1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--5EYxYxdGG1"
      },
      "source": [
        "# Determine indices for test and training data (outer loop partition)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mtw_XtXUpfk5"
      },
      "source": [
        "import random \n",
        "values = np.array(range(0,177))\n",
        "test_indices=[]\n",
        "training_indices=[]\n",
        "\n",
        "for i in range(0,100):\n",
        "  random.Random(3).shuffle(values)\n",
        "  training_id, test_id  = sklearn.model_selection.train_test_split(values, train_size=0.9, test_size=0.1)\n",
        "  test_indices.append(test_id)\n",
        "  training_indices.append(training_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVlBGs1KdYwM"
      },
      "source": [
        "# Train and test model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZlRgFtEiUsw"
      },
      "source": [
        "# grid search parameters\n",
        "C=[1,2,4, 8,16,32,64,128,256,512,1024]\n",
        "Gamma=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
        "\n",
        "tuned_parameters = [{'kernel': ['rbf'], 'gamma': Gamma,\n",
        "                     'C': C}]\n",
        "\n",
        "best_parameters=[]\n",
        "rsq=[]\n",
        "msq=[]\n",
        "for i in range(0,100):\n",
        "  train_dataset=dataset.iloc[training_indices[i],]\n",
        "  test_dataset=dataset.iloc[test_indices[i],]\n",
        "\n",
        "  train_dataset_nump = train_dataset.to_numpy()\n",
        "  test_dataset_nump = test_dataset.to_numpy()\n",
        "  train_dataset_nump = train_dataset_nump[:,2:-1]\n",
        "  test_dataset_nump = test_dataset_nump[:,2:-1]\n",
        "\n",
        "  scaler = StandardScaler() #Normalize training and test data.\n",
        "  train_dataset = scaler.fit_transform(train_dataset_nump)\n",
        "  test_dataset = scaler.transform(test_dataset_nump)\n",
        "\n",
        "  train_labels=train_dataset[:,0]\n",
        "  test_labels=test_dataset[:,0]\n",
        "\n",
        "  np.delete(train_dataset,0)\n",
        "  np.delete(test_dataset,0)\n",
        "\n",
        "  X_train = train_dataset\n",
        "  y_train = train_labels\n",
        "  X_test = test_dataset\n",
        "  y_test = test_labels\n",
        "\n",
        "  # Grid search with SVR estimator.\n",
        "  # Inner loop.\n",
        "  clf = GridSearchCV(SVR(), tuned_parameters, cv=10) #R^2 is default scoring function.\n",
        "\n",
        "  # Train model.\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  # Save parameters from best-fitting model.\n",
        "  best_parameters.append(clf.best_params_)\n",
        "\n",
        "  # Predict EDSS on trained model using test data.\n",
        "  y_true = y_test\n",
        "  y_pred = clf.predict(X_test)\n",
        "\n",
        "  # Calculate and save metrics \n",
        "  rsquare_svr = round(r2_score(y_true, y_pred),4)\n",
        "  rsq.append(rsquare_svr)\n",
        "\n",
        "  msq_error=mean_squared_error(y_true, y_pred)\n",
        "  msq.append(msq_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9HWMzMmD_wS"
      },
      "source": [
        "# Display mean R-squared\n",
        "mean_rsq=statistics.mean(rsq)\n",
        "print(mean_rsq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8QmouZJ7UbC"
      },
      "source": [
        "# Display mean mean-squared error.\n",
        "mean_msq=statistics.mean(msq)\n",
        "print(mean_msq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBUXir3pxx1t"
      },
      "source": [
        "# View all best parameters (100 total)\n",
        "best_parameters"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}